{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Libraries\n",
        "import pickle\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Load the Training Data\n",
        "path_to_flatland_train_data = '/content/sample_data/flatland_train.data'\n",
        "with gzip.open(path_to_flatland_train_data, 'rb') as f:\n",
        "    X_train, y_train = pickle.load(f)\n",
        "\n",
        "# Check the shapes of the data\n",
        "print(f\"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}\")\n",
        "\n",
        "# Step 3: Normalize and Prepare Training Data\n",
        "X_train = X_train.astype(np.float32) / 255.0  # Normalize pixel values to [0, 1]\n",
        "X_train_tensor = torch.tensor(X_train).unsqueeze(1)  # Add channel dimension\n",
        "\n",
        "# Convert labels to LongTensor\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Ensure correct data type\n",
        "\n",
        "# Create DataLoader for training data\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Step 4: Load the Test Data\n",
        "path_to_flatland_test_data = '/content/sample_data/flatland_test.data'\n",
        "with gzip.open(path_to_flatland_test_data, 'rb') as f:\n",
        "    X_test = np.load(f, allow_pickle=True)\n",
        "\n",
        "# Since X_test is a tuple, extract the first element\n",
        "X_test = X_test[0]  # Shape should be (10000, 50, 50)\n",
        "\n",
        "# Normalize the test data\n",
        "X_test = X_test.astype(np.float32) / 255.0\n",
        "X_test_tensor = torch.tensor(X_test).unsqueeze(1)  # Shape will now be (10000, 1, 50, 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ERnaRt-CH70",
        "outputId": "227c34c9-8d30-4354-991f-06f3cf6387a3"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (10000, 50, 50), Training labels shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Load the Training Data\n",
        "path_to_flatland_train_data = '/content/sample_data/flatland_train.data'\n",
        "with gzip.open(path_to_flatland_train_data, 'rb') as f:\n",
        "    X_train, y_train = pickle.load(f)\n",
        "\n",
        "# Step 3:  Augment and Prepare Training Data\n",
        "# Define transformations for data augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),  # Convert to PIL Image\n",
        "    transforms.RandomRotation(15), # Random rotation\n",
        "    transforms.RandomAffine(0, translate=(0.1,0.1)), #Random translation\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "])\n",
        "\n",
        "X_train = X_train.astype(np.float32) / 255.0  # Normalize pixel values\n",
        "\n",
        "# Apply augmentations\n",
        "augmented_X_train = []\n",
        "for img in X_train:\n",
        "    augmented_X_train.append(transform(img))\n",
        "X_train = np.stack(augmented_X_train)\n",
        "X_train_tensor = torch.tensor(X_train)\n",
        "\n",
        "# Convert labels to LongTensor\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Ensure correct data type\n",
        "\n",
        "# Create DataLoader for training data\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Step 4: Load the Test Data\n",
        "path_to_flatland_test_data = '/content/sample_data/flatland_test.data'\n",
        "with gzip.open(path_to_flatland_test_data, 'rb') as f:\n",
        "    X_test = np.load(f, allow_pickle=True)\n",
        "\n",
        "# Since X_test is a tuple, extract the first element\n",
        "X_test = X_test[0]  # Shape should be (10000, 50, 50)\n",
        "\n",
        "# Normalize the test data\n",
        "X_test = X_test.astype(np.float32) / 255.0\n",
        "X_test_tensor = torch.tensor(X_test).unsqueeze(1)  # Shape will now be (10000, 1, 50, 50)\n",
        "\n",
        "\n",
        "# Step 5: Define the CNN Model (Improved architecture)\n",
        "class ImprovedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32) # Batch normalization\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # Add another convolutional layer\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 256)  # Adjust input size for the first FC layer\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout for regularization\n",
        "        self.fc2 = nn.Linear(256, 7)  # 7 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = x.view(-1, 128 * 6 * 6)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)  # Apply dropout\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, define the loss function and optimizer\n",
        "model = ImprovedCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "RHYEP_EFKtO3"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Train the Model (Increased Epochs and potentially adjusted learning rate)\n",
        "num_epochs = 25  # Increased number of epochs\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)  # Slightly reduced learning rate\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = correct / total\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NZ2YWxnRsRn",
        "outputId": "d6016bae-3195-47c7-f8ab-f26966d500d7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Loss: 0.2129, Accuracy: 0.9355\n",
            "Epoch [2/25], Loss: 0.2020, Accuracy: 0.9419\n",
            "Epoch [3/25], Loss: 0.1843, Accuracy: 0.9427\n",
            "Epoch [4/25], Loss: 0.1840, Accuracy: 0.9441\n",
            "Epoch [5/25], Loss: 0.1784, Accuracy: 0.9451\n",
            "Epoch [6/25], Loss: 0.1672, Accuracy: 0.9449\n",
            "Epoch [7/25], Loss: 0.1612, Accuracy: 0.9488\n",
            "Epoch [8/25], Loss: 0.1697, Accuracy: 0.9440\n",
            "Epoch [9/25], Loss: 0.1610, Accuracy: 0.9459\n",
            "Epoch [10/25], Loss: 0.1523, Accuracy: 0.9507\n",
            "Epoch [11/25], Loss: 0.1433, Accuracy: 0.9512\n",
            "Epoch [12/25], Loss: 0.1433, Accuracy: 0.9526\n",
            "Epoch [13/25], Loss: 0.1331, Accuracy: 0.9526\n",
            "Epoch [14/25], Loss: 0.1270, Accuracy: 0.9574\n",
            "Epoch [15/25], Loss: 0.1389, Accuracy: 0.9510\n",
            "Epoch [16/25], Loss: 0.1410, Accuracy: 0.9491\n",
            "Epoch [17/25], Loss: 0.1288, Accuracy: 0.9520\n",
            "Epoch [18/25], Loss: 0.1150, Accuracy: 0.9600\n",
            "Epoch [19/25], Loss: 0.1167, Accuracy: 0.9584\n",
            "Epoch [20/25], Loss: 0.1098, Accuracy: 0.9588\n",
            "Epoch [21/25], Loss: 0.1114, Accuracy: 0.9580\n",
            "Epoch [22/25], Loss: 0.1231, Accuracy: 0.9581\n",
            "Epoch [23/25], Loss: 0.1016, Accuracy: 0.9605\n",
            "Epoch [24/25], Loss: 0.1071, Accuracy: 0.9617\n",
            "Epoch [25/25], Loss: 0.1103, Accuracy: 0.9566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, test_predictions = torch.max(test_outputs, 1)\n",
        "\n",
        "# Step 8: Format Predictions\n",
        "predictions = ''.join([str(round(p.item())) for p in test_predictions])\n",
        "print(f'Predictions: {predictions[:10000]}...')  # Print the first 50 predictions\n",
        "print(f'Total predictions length: {len(predictions)}')\n",
        "\n",
        "# Print distinct value count\n",
        "distinct_values = len(set(predictions))\n",
        "print(f'Distinct value count: {distinct_values}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjN1253pR1Id",
        "outputId": "c6c200c4-b204-4a76-c6be-3eec3501c07e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: 6545533343400053340545565645540453060355060333004303364356664054653303655503053350530604000355356463530403356355355050035360550004555530445455543654355046545635635536546303536656366660360305605463535336353336335465363306053565553360450055500063545060346553500453033465445556354503340300344553655053533306454055303443403030006300004655506334560544330054356500443044350645463346000306555305553645056355533336636330650645345554354535053654433053304055554504505345653050664300303445544604030306345006564333500506536544330334035643435343650403330363553435603566403440550043403430450565605303434536654355435035004453056564566035403330463455364406563043555443345350563053556660664633336350334356345353353060333043543433604546433334035630064450544503643600603355633556300553303033030463444500646463433660505604356455636403330035505464056664430653033355340544530633543635653365030035430440356635344063550033036433354560635035540504640055354350360630655656404363635646435404000566355305355503035300453666355506455560355005300453065344643064505003550633033300355365465353044363455065305346550453546603355040336344366506666034530635645460030055544643636564555666535604535433533403550463455534636504300045363464434440365505540353066533436455505544440035566563454365006566334333654054465343003434405346455433440434544330354634665055636553360466365565544065036404305464055003065363640543506034066346345665353030653036546534303465663566303500330536363536333435336066330634653335543636533053654463545460404363030446655330335664353535300053333343453445054035506334303000405403305345440066456554646036363046453563443444334335364535344333506433446553504646563540503053035665330636553505563434335030303664056630335564353604046560546546334665046035655633405050533564435535053604534405566050353534050035445565535546505453535630533053453436653543544605055500040536054436563044440033550300355603465030335635305543503564033033543435605055653346400556563553466463556044360306553305600056344066563654063550300655335563436354636400330654340533355566545300563355535004040300460055555046565654663363660554645500503003630050436003064440505564505645630346355433505630005404605444333403544403363305534536435445550603545405353053336346063545366004535505064343043033336453305430466340455433534534536333503366665553334454634033053654043354465535550535533356333434535563564435035503535343436354553635550440500435056346506554665640553644340635346054344305443504645543555060034445435435005505556056505054364430550463305065506035636005634355034453356443436333404335350634644440440555563035040636333635454364445040543006505653655360446635564036306434633000545564004634466356330350345040343305300544054345036344534604564430665300406543045354343330335335056053464306503346334556006635536303345560553600600654453633334605505530605454535403050344435456553034040063405653664645535355400353400465565536430003633563335533605046403603530434654540343400463655530433000355655550305343665335630366533060345044000350504444543035603563050306033344565436655030343530345565005546533663060360530635500665336003655054533553303006504450450634554635533463300535503360030660050505034634554335060445450303343443053555544335343330055464546043354344635436445335043030363350533055033603455534653353030644354304633634630330606330045505005603635345535334344405354533645505543543504363450364430445430535344505443000665533404304563404655565353500035505645536635363336405044460044604306453445053003540545453505544543530653430366663560334463546064033535564663345350534036465533500356556554334504645300445435043330000534403446344565465064555063655545055533536530450566630663355553363553463466305046534303540053455355355555536434054605033445343434050664556350435336343633055530045455040560055445633006044355553444330444503453350403504340535330335464553365063505053665400503353035363405346543630644463644305400303060645663350066304453636660043503355334063054500054040500435660540556663334534335330353453554350300366304455563446334043305004353335654660550335543340634444663060545650554536434443463400404005455505436460500000063553330560664665303305653355000653435355565645555533505335063560563500663635654630534444355055343545305656664645306563450036040463034550033543340364563565563603504656056603530666030534404035343554053034363054364055356554355303463565306545363406335634546546653500550646604344500345436643530505536343435300353543530363536605330535535304535565454064634606655366353545346356400430305533555000345360535005663053443654636635650630534606340065306304560364633455355455503600054533434355446366440360630650553503445630334353043044603354035330305460533640405355666643050563433333663636354435463033530543635356430056500034363434554334333055005330554643563563440005464450305003056540543634503300000633634654433533565505565343540005454453634435034463445603040555543540533344640433530643355406440604650644404605630003653553300563533334050335644403500464555460453506546504365350563343646335604355344455540443303500303665640650333503346330533450454550036656053504334340533036435336553636530540553343006003330655604503650663344653363444343663450355556335633503554563304505665535636306444060464603545456566453534336536540406656533060346540545555403630555336443430440603363034635555556354554343330053634305340665403044333433460543535530564563303565553304360336430336065056356063533003460635034533043053054540060036300356354434503564533544543653546604430646536035564633455530303564346033503536400004563655304545563433053043636330443454434545340353556343360363635030063455036330655043460505456545343405653406403335655055053040505443034063506000333563006535035044500056303030055603630553036054303056460464534033540565335333655553564553045305405444533655554604503334034644435660403453063500335600045334336060344456054053533005446555553653633656640334005336503056533563644006653534363303406345503035354304433604636333345630035066355354333003344645666445550045440564643500305553344056334545404344355605546040055334635300555304564403405530565534306344665535535040454454464436343564060633305646650543634053335334450346434300360600634655040034055403404555303436534306645364344605540050354336000550353503550003545635360340350400563433550560034343635030336336565364334536555443540044035303306360664354433033643354443033605035353445336404453306045053050603036553554055540464463066560555444333065544503534354655366400650354460060465556363354350043655055436356634033046360355663506064350430655634430604333533530533363536043000634504656330555033035055345555340534436553303436656453433363543404503543454456655363344340505304503036030553363000533064430503055304005335335340356333430463554555443506554053560346363034036353544054553030334306500364063534560654506643556535343006544030365646560005356333553533003404553354035530466454034563006435543303606565035443353633353366300365530055456456430533333464440565336533353456553665355645400400534054630534306653646560044540455345533434634664536555360366435355633450035446333506553566465354553446355343355536663503560450544446553335604443646033464333400303606665000360350305054035655065400456434634666650536065630463504033443545044300353465355635464350666465550636540355545035350356400655366356604354560553635304353535043650305033053545363046606356365604330543604063466644305533353666333504333354663534364645533345356504504555040406434544454356564333645530330500050535433433630464636336560656536504340045344356466665666034350063335553605530456504350346334443665535660364445543440435406050000565564445436305336555356455343303333355446563463530534563465305650333534063335056335304304000050055640544053344000455644550505066063600543303630503035660036544535364054544653055434033533360400443555305535656534560043343553363656544456065540304550660345606004403606046555553433536355533330303005533456406663556303330535536605005656300366345355004433443540563065530004554064345055436333653346346053034054050634356006505443045446366333333055346655050603566335045366534444060063640304563335643630343343005033555443656563565406655654353435545403005353303635300303656305604463503305500036656530354004356545643440403360303065550463550044534633450603660306354345536435433465464433555000336334504455646643343430406533556534555434430560335463543030644433440334640630346064304453403545533436636563455054443633546633550035304403544045303633504436535403605363550443560300453660350655356450346533003336033366453456546543366460440534430645530340303556645434036355304345305034405003344455003006330665660640033645305463460354403553065534534533300330045545535655655554033505350334500405343404454635566655505503564555464030430005665306334560333036455644500553004560335653563304345035430304635434033303304405454663545054043033430045064660066635463300036344546636536335555555445355053640543034350665333366445650605464503305063353430453543563500553353343555335555554003555660353346400030554033300453036353664455533540453305645453500063600500454363666566364363303605665564363555004440336066640354504530034446445644336654646304033046344355433356633530363554333340353356005605565560535365053556360450005436450436034466535356350555446333634335355033334433063444300535453536000505304650555405464555563645464053033350363045430636056543555555530556005635343664004033543645033560036656555643630504355533504553354034436355345303533504433650654530006366663034553030035350450565504334653366344365453065503034330333630530003633634305360000004565046665404300553443504300635036560063465355645533355663535000456066005333033004453656303556365300666535306335544356354653550660340344605355650466503403455353656065545003033343433440363506633345665405455636056035400305546033553303355305365503400306334536533654005053534463443345035344350636030505463055035333045454000354630655450354430453346555030656635400434350533445036060346565343505656636365033350436054455046356450456444555466643030566334335550003454633635643444030034646404500603056355005535363554506650550605555500350004344634543445334405306366554450404555050665603354045533354655533533440564456444305553000605445505333644035433405430035...\n",
            "Total predictions length: 10000\n",
            "Distinct value count: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Šitas modelis su test data gavo visai neblogą tikslumą 86%. Tačiau norisi dar didesnio tiklsumo.\n"
      ],
      "metadata": {
        "id": "7MocQs7E-IBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bandome dar labiau stiprinti modelį, pridedame conv sluoksnį, transformuojame paveiklsiukus dar kartą, kad geriau treniruotųsi modelis."
      ],
      "metadata": {
        "id": "5Ke1y-sm-cdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Improved Model Definition\n",
        "class EnhancedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EnhancedCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)  # Larger kernel size\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # Extra layer\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 3 * 3, 256)  # Adjust for additional layer\n",
        "        self.dropout = nn.Dropout(0.6)  # Increased dropout\n",
        "        self.fc2 = nn.Linear(256, 7)  # Final output layer for 7 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = x.view(-1, 256 * 3 * 3)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the improved model\n",
        "model = EnhancedCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Added weight decay\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # Learning rate scheduler\n",
        "\n",
        "# Improved data augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation(20),  # Increased rotation for variation\n",
        "    transforms.RandomAffine(0, translate=(0.2, 0.2)),  # Increased translation\n",
        "    transforms.RandomHorizontalFlip(),  # Added horizontal flip\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Slight brightness/contrast\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Apply the updated transformations to training data\n",
        "augmented_X_train = [transform(img) for img in X_train]\n",
        "X_train = torch.stack(augmented_X_train)\n",
        "\n",
        "# Redefine the DataLoader with updated data\n",
        "train_dataset = TensorDataset(X_train, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Training Loop with Learning Rate Scheduler\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy on the training batch\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    # Step the scheduler after each epoch\n",
        "    scheduler.step()\n",
        "\n",
        "    # Calculate epoch accuracy\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "\n",
        "    # Step the scheduler after each epoch\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov7yBQTfpRt8",
        "outputId": "3d278b89-85cd-473f-e809-660e4f09c8bc"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 1.0935, Train Accuracy: 53.61%\n",
            "Epoch [2/20], Loss: 0.6921, Train Accuracy: 73.80%\n",
            "Epoch [3/20], Loss: 0.5392, Train Accuracy: 82.01%\n",
            "Epoch [4/20], Loss: 0.4850, Train Accuracy: 84.65%\n",
            "Epoch [5/20], Loss: 0.4577, Train Accuracy: 85.55%\n",
            "Epoch [6/20], Loss: 0.3635, Train Accuracy: 90.13%\n",
            "Epoch [7/20], Loss: 0.3284, Train Accuracy: 91.48%\n",
            "Epoch [8/20], Loss: 0.3106, Train Accuracy: 92.26%\n",
            "Epoch [9/20], Loss: 0.2810, Train Accuracy: 92.90%\n",
            "Epoch [10/20], Loss: 0.2598, Train Accuracy: 93.72%\n",
            "Epoch [11/20], Loss: 0.2220, Train Accuracy: 95.07%\n",
            "Epoch [12/20], Loss: 0.2068, Train Accuracy: 95.40%\n",
            "Epoch [13/20], Loss: 0.2007, Train Accuracy: 95.55%\n",
            "Epoch [14/20], Loss: 0.1903, Train Accuracy: 95.52%\n",
            "Epoch [15/20], Loss: 0.1760, Train Accuracy: 95.92%\n",
            "Epoch [16/20], Loss: 0.1598, Train Accuracy: 96.43%\n",
            "Epoch [17/20], Loss: 0.1501, Train Accuracy: 96.56%\n",
            "Epoch [18/20], Loss: 0.1369, Train Accuracy: 96.65%\n",
            "Epoch [19/20], Loss: 0.1251, Train Accuracy: 96.82%\n",
            "Epoch [20/20], Loss: 0.1219, Train Accuracy: 96.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, test_predictions = torch.max(test_outputs, 1)\n",
        "\n",
        "# Step 8: Format Predictions\n",
        "predictions = ''.join([str(round(p.item())) for p in test_predictions])\n",
        "print(f'Predictions: {predictions[:10000]}...')  # Print the first 50 predictions\n",
        "print(f'Total predictions length: {len(predictions)}')\n",
        "\n",
        "# Print distinct value count\n",
        "distinct_values = len(set(predictions))\n",
        "print(f'Distinct value count: {distinct_values}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s038nZbCoulU",
        "outputId": "35dc8a4c-6638-456b-cc1a-aafd3691ff36"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: 6045533343400053340545465645540403050355550333004303354306654054553303655503043350530654500355355463530403305345345040035360550004555530445455543654345046545535535536546303536556365650350305505463535335353336330465353306053555453360450054500063440060345543400453033455445546354503345300344553655053533306444055303443403030505300054055506334500544330054354500443044350645463346000306504305053645045350533336636330650544345504354535003644433053304055544504505345553050664300303444544504030306344006554333400506036544330334035643434343650403330363543435603556453440550543403430450565505303434536554355435035004453005464505030403330463450354406563043554443345350553053555600564533336350334356344353343060333043443433504546433334035530054450544503643600503355633556300553303033030463444400546453433660505604345455536403330035505464056564430553033355340544530633543635653364030035430440356534344003555033036433354550635035440504640055344340350630645656404363635646435404000560355305354503035300453655355504454550305055300453055344643054505003540633033300355360455353044363454065305346550453446603355040335344366406565034430635645460030055644643435454555660535504534433533403050453455534035504300045363454434440365505440353066533435455505544440035566563444365005405334333654054465343003434400340455433440434444330304534555050636553350465365665444065035404305464055003065363640443506034056346345655303030553036545534303465653556303500330536353435333434335065330534555335543635533053604453544460404363530445655330334564353535300043333343453445054535556334303000404403305345440056456554646036363046453563443444334334354535344333565433446553504540563540503053035565330530553405553434335030303564055630335554353604545060446545334650046034645633405050533554434534053504534405565040353534050034445565535546505453535530533003453436503543544605055500045536044436503044440033040300305503465030335635304543503554033033543435604055553346400555503443446453556044360305553305600055344056563654053500300650335553436354636400330604340433345565444300563355535004040300450055555046565554663363560554645500503003630050436003054440505564505645630346355433505530004404455444333403544403353305434535435445550503045400353043335340063545366004535504054343043033336453304430466340450433534534536333403355650553334454634033053554043354455530050535533346333434535453454434035503535343436304553634550440500435055344605454655640553544340035346054344304443504045543550060034444434435505505545055505054364430550453300065555535536005634355534443355443435333404335350534644440440545463535040636333630444354445040543006005653655300446635564036306434533005445454004434466356330350345040343305300544054345035344534504554430560300405443045344343330335330056053454305403345334556006634436303345550553600550654453633334505505530605404535403560354435456553534040053405653504645535345450353400455565535430003533563334533500546403603030434654540343400453654430433000355655550305343554330630366533560345044400350004444543035603563050306033344065435655030343535340550005545533663560360430535500665335003055054533553303006404450450634554535533463300535503360035560050405034434454335060446450303343443055545544330343330055464546043354344530436445334043030353350433055033003455534653353030644354304633034535330606330045505005053635345535334344404354433645505543543504363455364430445430535344505443000655533404304553404645565353500035505645536635353336405044460044504306453444053003540444443005544043530503430364663560334403546004033535564663345340534036465533500355556544334504545305440435043330000534403445344565465064554063655545050533536530450566530553350543363553453446305045534303040053455305305555530434004604033444343434050564556305435335343533055430044454540550054440633506044355503444330444403453350403504340435330335464553355063505053660400503343035363405346543530544463644305400303540645053340066304453536660043403354334553054500044040500435660540056563334434335330353453544350300356304455553445334043305004353335554650055335543340534444563060545650554536434443453400404005455505436450500000063443330560564655353305643355000503435355555545555433400335003565563500653635654630534444345055343545305606654644306463450036045463034550033543340354543564563503504656054403030566030534404035343554053034353044364045305544355303463560305545363406335534546046653500550646504344500345435543530505536343435300303043530353436605330535535304035505454054034506555366353545345354400430305533554000345350535005653003443654636635650630534606340055305304565354633455355455503600054533434355446356440350530650453503444530334353043044603354035330305450533040405355656543000503433333663536354435463033530543635355430055500034353434554334333055005335554043463563440005464440305003046440443634503300000633534554433533565005555343540005454463634435034463445603540555543540533344640433530543355406440604555644404605530003653553300553533334050334644403000464445460453506046504355350553343645335604355344455540443303500303655540650333503344330533450454450036605053604334340533035435336553535530550553343006003330555604503050563344553353444343653450350545335533503054553304506665535036305444050464503445456556453534336536440405656533060345540545544403630555336443430440603353034634556505344404343330053634304340665403044333433450543535530554563303565553304360336430335065505306063533053460635034533543053054540060036350355354434403564433444543653546504430645430035564033455530303564346033503536400004553555354546063433053043036330443444434545345353456343360363635030063454035330055043460505456545343405653405403335555055043040504443034063506000333553005535035544500056303030005603630553035054303055460454534033540455335333405453554553040305405444433504554604553334034544435650453453053500334600045334336050344455054053533004446555543553633656640334005336503056033453644005653534363303406344503035354304433504636333345630035065355354333003344545665445540045440564543500305553344056334545404344355605545040055334535300554304564403405530555534306344665535530040454454454436343564050633305545550543634053335334450346434300360500534555040034005403404555303435534306645354344655040005354334000550353503550003545435355345350400553433550550034343635030336335564354334536054443540044030303306360554344433033543304443033605035353445336404453306045053050603036553544055540454463055550545444333055544403534354655356400640354460050465545363344350043650055435356634033044360355653505054350435655634435604333433530533363536043000634404655330505033035055345004345034436553353435656453433363543404503443454456645363344340505304503036530553363000533054430503045304005335335340356333430463554555443005544053550345363034035353544044553030334305400354063434450554506643556535343006544030355546560005356333453533003404553354035430466444034553006435543303506565035443353033353366300365535055446456430533333564440554336533353455553665355645400400534054630534300653545560044540450345533434634654536545360355435350633450535445333006503055464304543446355343355035653503550450044445543335604443540033454333405303605065050360350355044034645064400455434434566640536065430463504033443545044300353455345635464350666454450636440355540030350356400645365356404344450453535304353034043650305033053545303046606356345604330543604053466644305533353565333404333354653534354545433345356404404555040405434544454345464333645530336500050535433433630454536335550556035504340045344356466565665034350063335553505430456504345345334443665535560354444543440430406040000054554445436305335544355455343303333345446563453530534053465305650333534043335056330304304000050055640554053344000455544540504066063600543303630503034660036544435354054544603005434033533360400443555305034656534550043343503363656444456054540304050550345600004403606046455053433536355533330303005433456405553556353330534535655005656300366345355004433443540543065530004554554344055435333553345345053034004050534356005505443545445366333333055346555050503055335044365534444050063545304463335643530343343005033545443546553565405555554353435545403005353303535300303455305604463503306500036656530354004354545643440403350303065450443450044534633440603655306304345535435433464464433450000336334504455646643343430405433555534554434430460334463543030644433440334640630346054304443403544533436635563455054443633545033550035304403544045303533504436530403604353550443560300443650340655356450346533003335033366453455545443360460440534430645530345303456645434035350304345305034406003344450003006330665650645033545305463460304403453055534534533300330044545535655555554033505350334500405343454454635565655405503464555454030430005565306334560333036455644500043004460335653553304344034430304635434033303304405454663545004043033430045064450056634453300035344546636436335555505445354053540543034350655333366445650605454503305053353430443543563500553303343505335555554003555650353346400035554033300503036353664455033540453305645453460063000500454363656555354363303604565064363555004440336065640304504530534440445544335664645304033046344355433355633530363444333340353355005605565560435364053556360456000430450435034465435356350545445333534335345033334433063444300534443536500505304650555404454555563545454053033340363045430536056443555454530546505635343654004033543644033560035506555543630004345033504543354034435355345303033554433650654530505366653034553030034340440560004334653305344354453065503534330333530530003533634305350000004554046665404305553443504300535036560063455355545533345653436000445066005333033004453655303556364350605536306335444356354553550660340344505355550466503403455353640055545003033343433440353506633344665405455636050035400305045033553303345305365503450305334436533555005053534453443345035344340630030505403055035333045454000354530655450354430453346455030656535400434350533440035060346555343500646636355033350435054455046355450455444555450543030556344335000003404533630643444030534545404500603046355004535353554506650550504554500350504344534543445334405306356454450454545050555603354040533354654533433440564455444305553000605445505333644035433405430535...\n",
            "Total predictions length: 10000\n",
            "Distinct value count: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Su šituo modeliu gauname 90% tikslumą, vadinas pridėjus conv sluoksnį, transformuojant paveiksliukus, galime gerinti modelio tikslumą."
      ],
      "metadata": {
        "id": "VBxDiLlL_hCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Modelio efektyvumas: 90% tikslumas rodo,\n",
        "kad modelis gerai atpažįsta ir klasifikuoja\n",
        "figūras.\n",
        "\n",
        "* Overfitting: reikia atsargiai su conv sluoksniais.\n",
        "\n",
        "* Klasės balansavimas: turime įvertinti, ar duomenų rinkinys yra subalansuotas. 90% tikslumas gali būti klaidingas, jei modelis gerai klasifikuoja tik dažniausiai pasitaikančias klases, tačiau prastai atpažįsta retesnes klases.\n",
        "\n",
        "* Tolimesni patobulinimai: Nors 90% yra geras pasiekimas, visada galima ieškoti būdų, kaip pagerinti modelio veikimą. Galima išbandyti skirtingas architektūras, optimizavimo metodus, duomenų didinimą (data augmentation) ar hiperparametrų derinimą. Arba naudoti jau ištreniruotus modelius, bandyt juos taikyt savo duomenims.\n"
      ],
      "metadata": {
        "id": "cfrkWCuvDURK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-QLZIyGVBWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import models, transforms\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "azMdru9ZcK87"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Data Augmentation\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Reshape X_train_tensor to (num_images, channels, height, width)\n",
        "# Assuming grayscale images, channels = 1\n",
        "X_train_tensor = X_train_tensor.reshape(-1, 1, 50, 50)\n",
        "\n",
        "# Augment training data\n",
        "augmented_X_train = [data_transforms(img) for img in X_train_tensor]\n",
        "X_train_tensor = torch.stack(augmented_X_train)"
      ],
      "metadata": {
        "id": "fGl8t9X2cb8H"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define a CNN Model using Transfer Learning\n",
        "class CNNTransferLearning(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNTransferLearning, self).__init__()\n",
        "        # Load a pre-trained ResNet model\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        # Modify the first convolutional layer to accept 1 channel input\n",
        "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False) #changed input channel to 1\n",
        "        # Modify the last layer to fit our number of classes\n",
        "        num_ftrs = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_ftrs, 7)  # Assuming 7 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1, 50, 50)  # Reshape for CNN input\n",
        "        x = self.resnet(x)  # Forward pass through ResNet\n",
        "        return x\n",
        "\n",
        "# Step 5: Initialize the Model, Loss Function, and Optimizer\n",
        "model = CNNTransferLearning()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Step 6: Training Loop with Early Stopping\n",
        "num_epochs = 5\n",
        "best_accuracy = 0\n",
        "patience = 5  # Early stopping patience\n",
        "counter = 0\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in DataLoader(train_dataset, batch_size=32, shuffle=True):\n",
        "        images, labels = images.to(device), labels.to(device)  # Move to GPU if available\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy on the training batch\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    # Calculate epoch accuracy\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw-6wWmQcDsp",
        "outputId": "b498f2ee-ac5e-45b5-aa7f-7b9a58e2da47"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.3373, Train Accuracy: 90.22%\n",
            "Epoch [2/5], Loss: 0.1465, Train Accuracy: 97.34%\n",
            "Epoch [3/5], Loss: 0.1431, Train Accuracy: 97.46%\n",
            "Epoch [4/5], Loss: 0.1273, Train Accuracy: 98.04%\n",
            "Epoch [5/5], Loss: 0.1415, Train Accuracy: 97.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: evaluate and print prediction cnntranderlearning model\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    X_test_tensor = X_test_tensor.to(device)  # Move test data to the same device as the model\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, test_predictions = torch.max(test_outputs, 1)\n",
        "\n",
        "predictions = ''.join([str(round(p.item())) for p in test_predictions])\n",
        "print(f'Predictions: {predictions[:10000]}...')  # Print the first 1000 predictions\n",
        "print(f'Total predictions length: {len(predictions)}')\n",
        "\n",
        "# Print distinct value count\n",
        "distinct_values = len(set(predictions))\n",
        "print(f'Distinct value count: {distinct_values}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG0UyzhncNPj",
        "outputId": "89f0a596-2cbd-467a-a24f-3e91bd73b46e"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: 6545533343400063340545565645530453050355660333004363364366664054553303655503033350530654600355355463530403355335355050035350650004555530445455543654355046545635635636556303536656365660360305656463535336353336335465353306053566353360450055500063345060346653300453533455445556354503345300354553655053533306454055353433403030605300053555506334560544330054353500343044350645463346050306555305553645055355533336636330650643345554354536053654433663304055554504505345553050664300303455544505030306345006554333500506536544330334035643533353650403330363553435603556553440550543403430450565505303534536654355435035003453056564566035403430463455364506563043555543345350553053566650564533336350334356345353353060333043553433504546443334036630054450544503643600503355633656300553303033036463444500536453433660505604355456536403330035505464066563430553033355340544530633643635653365030035530440356535334063556033036433354550635036340504640055344330360630655656404363635646435405000566355305365503035300453665355503455560355055300453055344643054505003650633033300355366455353044363455565305346550453346603355040336334366306566035530635645460030055654643336554555666535604535533533403555553455534535504300035363464434540365505540353066633435555505544440035566563454365006555334333654054465343003435460346555433440435554330354534565055636553350466365565543065035504305463055003065363646443506034056346355655353030563036546534303465663556303500330536353535333435335066330534556335543636533063654363545460404363630455655330335563353535300033333343453445054535566334303000403503305345440055456554646036363046453563443444335335364535354333565433546553504546563650503053535565330536553505563434335030303564055630335564353604646560546546334655546035655633405050533553433535053504534405566030353534050035545565535546505453535630533063453436563553554605056505035536054436553044440033550300355503465030335635305543503564033033543435663056553346400556563353436463556044360305553306600055334056563654053560300656335553436354636400330654340533355565345300563355536004040300560055555056565654663363660554645500503003630550436003554440605565505646630346355433505630005304365444333403544503353305534636435445550504645406353033335346063555366004535505054343043033336453305430466350455433534535536333503355666553334454634043053654043355455535650535533356333434535563564435035503535343436354653635550450500435656345606554665630553544340635346054344305443504655543556060034445435535505505536056505054355430550453306065566535536005634355635453355533336333404335360535654440530555563535040636333635454354445040543006505653655360446635564036306434533005545554004534466356330350345030343305300554054345536344535604554430665300406543035354343330335335056053464306503345334506006635336303445550553600550654453633334506505530605454635403560355436456553634040053405653554655535355450353400465565536430003533563335533505646503603630434654550343400453655530533000355656550305343655335630366533560355044300350504454543035603563050306033344565535655030343535346556005546533663560360530535500665336003655054533553303006504450450634555535533463300535503360035660050505034335554335060446450303353443056555554335343330055465546043364344635436345335053030353350533055033503455534653363030645354304633634536330666330045505005653635345535333334305354533535505543543504363556364430445430535344505453000655533404304553404655565353500035505655536635353336405054460044505306453445053003540545453505545543530653430365663560334463546054033535564663345350534036465533550355556555334504545356546435053330000534503546355565465064555063655545055533536530550566530553365553363553453456305045534303540053455356356565536434054603033443343534050564556356435335343633055530045455546560055455633606045355553444330444503453356403504350535330335463553355063505053665400503333035363405346543530544463643405500303550645653350666304353636660043503355334563053500054040500535660540556663334535335336353453554360300356304455553456334043305004353335654660555335543330534444563060545650564536534443463400404005455505436460500000063553330566564665363305653355000563435365555645550533505335063565553500653635654630534444345055343545305656664635306563450036046563034550033543350354533565563503564656055303630566030535405035343554053034363054363055365553355303463565306545363506335534546646653500550646504344500345435643530505536343435300353643530354336605330535535304535555454054634506555366353555345355400430305533655000345360535005653053443654636635650630534606340065305305566354633355355455503600054533434355446356440350530650553503445530334353043044603354035330305450533640405355666543050563433333663636354535463033530543635355330065600034353435554333333065005335554633563563440005564550305003056540553634503300000633634654533533665505655343540005454463634435034463546603540555543540533344640433530543355406440604656645504605530003653553300553533334050335634504500464556460453506546504355350553343656335604355344455540443303500303655550655333503345330533455354550036656053604334340533036435336553535540550563333006003330555604503550663344653353444343653450355555335543504554563304506665535636305443056464503545556556453534336536340405656533060345640545555403630555336443530340603353034635556556354564353330053634305340665403044333433450643535530554563303565553305360336330335065655356063533053460635034533543053053556065036350355355434503564533344643653546504430646536035564633556530303564336033503536400004563555354546563433053043636330443454434545345353556343360363635030063555036330655043360505456545343405653406503335555056053040505543034064506000333553005535035654500556303030055603630553035054353055560454534033545565335333555553564563046305405444533555554604553334034654435660463463063500333600055334336050344466654053533005446555553553633656640334505336503056533563644006653534363303406345503035354304433604636333345630035066355354333003344645665345530055540564543500305553344056334555404344355605545040055334635300555304564403405530555533306343666535535040454455454436343564066633305656650553635053335334450346534300360600534655040034065403404555303435534306645354344665540055353333000650353503550003545535355346350400553433650650035343635030336335565364334536555443540044035303306360554354433033543354443033605035353445336404453306045053060603036503554055540464463055550555444333065544303534354655356400650354560050465555363354350043656055435356634033045360355653505054350435656634535604333533530533363636043000634404656330555033035055345655340534536553353436656453533363543404503543454456655363344340505304503036530553363000533054430503055304005335335340356333430563554555343506554053550346363034035353544054553030333305566364063534560553506643556535343006544030365536560005356333553533003404553354035330466454034553506435543303606565035443353533353366300366535055456456430533333564440553336533353455553665355645400300534053630034306653646560044540456345533434634654536555360355435355633450635445333506553656463353653446356343355535653503560450654446553335604443546033454333405303666665050360350365053035655565400456434534566650536065330463504033443546044300353455355635464350666455550636550355546035350356400655365356304354550553635364353535053650305033053545363046606356355604340543604063466644305533353665333564333354663534354645533345356504503555040305434554454355364333645530336500050535433433630465536335550556636504340045335356466665665034350063335553505530356504355346333443665535660354445543440535406036000555564456536305335535355455343303333335446563453530534053465365650333535053335056335304304000060055650554053345000456544550505066063650543303630503035660036544535364054544663055434033533360406443565305533656534560043333553363656344556565550304550550355606004403606046355553433636355533330303005533456305553556353330535535655005666300366355355004433443540553065530005555664343055436333553345345063534054050634356006506453545446366333333055346665050603565335045366534434050063546305563335643530343343005033555543656653665405655554353535545403505353303536300303355305604363503306550036656530354004353535643440403360303066550433550044534633430603655306354345536435433465564433550000336334504455646643343430405533655534555435430560335463533030544434440333640630346064304453403545533436636563455064443633645633550035304403554045303633504436535403605363550443560300453660350655356450356533003335033366453455545543366460450534430645530345303556655434036365304355305035406003354456003006330665650645033545300463460354403553056534534533300330045555535665555554033505360334500505343454403635565655555503564555554030530005665306334660333036455544500553005560335653563304345035430304645434033303304405454663545064043033430045064550056635453300036344546636536335655565345355053640543034350665333366445650605464503305063353430453543563500553353343555435555554003556660353346400035554033300553036353664455533550463305646453560063600500354363656555354363303605565664363555004550336065640354504530634445546544335664656304033046345355433356633530364554333340353355005605565560535365053556360465006536450436033565535356350555445333534335355033334433063444300535453536600505304650556405453555563645554053033350363035430536056543555555530556505635343663004033543645033560035656556653630505335633504553354534435355345303533554433650654530506366653034553030035350435565504334663365344355453065503534330333630530003533634305350000004555046665404305553553504300635036560563465355645533355663336000455066605333033054453656303656365350656536306335544356354553550666340344505355550466553403555353656055545003033343433430353506633343665405455636056036400405546033553303355305365503356306334536533555005053534453443345035344350635030505453055035333045354006354630655550354530453345555030656535400434350533445035060346555353505656636355033350536054455046355550455444555456543030556354335500003455533635643444030534546404500603056355005035353554506650550505553500350604344634553445334406356356554450455555050655603364045533354655633533440564455444306653000605545505333654035433506430635...\n",
            "Total predictions length: 10000\n",
            "Distinct value count: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import models, transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import ToPILImage # Import ToPILImage\n",
        "from PIL import Image\n",
        "\n",
        "# Step 2: Load the Training Data\n",
        "path_to_flatland_train_data = '/content/sample_data/flatland_train.data'\n",
        "with gzip.open(path_to_flatland_train_data, 'rb') as f:\n",
        "    X_train, y_train = pickle.load(f)\n",
        "\n",
        "# Check the shapes of the data\n",
        "print(f\"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}\")\n",
        "\n",
        "# Step 3: Normalize and Prepare Training Data\n",
        "X_train = X_train.astype(np.float32) / 255.0  # Normalize pixel values to [0, 1]\n",
        "#X_train_tensor = torch.tensor(X_train).unsqueeze(1)  # Add channel dimension\n",
        "\n",
        "# Convert labels to LongTensor\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Ensure correct data type\n",
        "\n",
        "# Data Augmentation\n",
        "data_transforms = transforms.Compose([\n",
        "    ToPILImage(), # Convert to PIL Image before other transformations\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Custom Dataset Class for Data Augmentation\n",
        "class CustomDataset(TensorDataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        # Convert to PIL Image if it's not already a PIL Image\n",
        "        # Removed unnecessary ToPILImage() conversion\n",
        "        #if not isinstance(image, Image.Image): # Check if it's a PIL Image\n",
        "        #    image = ToPILImage()(image) # Convert to PIL Image\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Create DataLoader for training data with Data Augmentation\n",
        "train_dataset = CustomDataset(X_train_tensor, y_train_tensor, transform=data_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Step 4: Define a CNN Model using DenseNet\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        # Load a pre-trained DenseNet model\n",
        "        self.densenet = models.densenet121(pretrained=True)\n",
        "        # Modify the first convolutional layer to accept 1 channel input\n",
        "        self.densenet.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False) #changed input channel to 1\n",
        "        # Modify the last layer to fit our number of classes\n",
        "        num_ftrs = self.densenet.classifier.in_features\n",
        "        self.densenet.classifier = nn.Linear(num_ftrs, 7)  # Assuming 7 classes\n",
        "        self.dropout = nn.Dropout(0.5)  # Adding dropout for regularization\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1, 50, 50)  # Reshape for CNN input\n",
        "        x = self.densenet(x)  # Forward pass through DenseNet\n",
        "        return x\n",
        "\n",
        "# Step 5: Initialize the Model, Loss Function, and Optimizer\n",
        "model = CNNModel()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)  # AdamW for better convergence\n",
        "\n",
        "# Step 6: Training Loop with Early Stopping and Validation\n",
        "num_epochs = 7\n",
        "best_accuracy = 0\n",
        "patience = 5  # Early stopping patience\n",
        "counter = 0\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)  # Move to GPU if available\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy on the training batch\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    # Calculate epoch accuracy\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdA8-mOqiLKI",
        "outputId": "c8abd7c1-86be-4293-ecdc-ef852f4ab1fd"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (10000, 50, 50), Training labels shape: (10000,)\n",
            "Epoch [1/7], Loss: 0.3671, Train Accuracy: 89.01%\n",
            "Epoch [2/7], Loss: 0.1774, Train Accuracy: 96.37%\n",
            "Epoch [3/7], Loss: 0.1376, Train Accuracy: 97.67%\n",
            "Epoch [4/7], Loss: 0.1255, Train Accuracy: 98.15%\n",
            "Epoch [5/7], Loss: 0.1369, Train Accuracy: 97.68%\n",
            "Epoch [6/7], Loss: 0.1237, Train Accuracy: 98.22%\n",
            "Epoch [7/7], Loss: 0.1226, Train Accuracy: 97.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    X_test_tensor = X_test_tensor.to(device)  # Move test data to the same device as the model\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, test_predictions = torch.max(test_outputs, 1)\n",
        "\n",
        "predictions = ''.join([str(round(p.item())) for p in test_predictions])\n",
        "print(f'Predictions: {predictions[:10000]}...')  # Print the first 1000 predictions\n",
        "print(f'Total predictions length: {len(predictions)}')\n",
        "\n",
        "# Print distinct value count\n",
        "distinct_values = len(set(predictions))\n",
        "print(f'Distinct value count: {distinct_values}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsejEH7jrPHH",
        "outputId": "fff2f2d1-ce0d-4360-f8a7-4008669c44aa"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: 6645533343400063340545465645540463050355660333004363364366664054553303655503043350530664500355355463530403365345345040035360650004655530445455543654345046545635635636546303536656365660360305666463536336363336336465353306053566453360450054500063446060346643400453633456446546354503346300344553655053533306444055363443403030605300054655506334560544330054364500443044350645463346060306564305553645045355533336636330660644345564354536003644433663304055544504505345553050664300303444544504030306344006554333400506036544330334035643434343650403330363543435603556403440550643403430450565505303434536654355435035004453066464566036403330463456364406563043554443345350563053566660564533336350334356344353343060333043443433504546433334036630054450544503643600503355633656300553303033036463444450546453433660605604345456536403330035505464066564430553033365340544530633643635653364030035430440356534344063556033036433354560635036440504640065344340360630645656404363635646435404000566355305364603035300453665355604454560366065300453055344643054505003540633033300355366455363044363454665305346550453446603355040336344366406566034430635645460030055644643436454555666535604534433533403656453455534635504300045363464434440365505440353066633435455505544440035566563444365006465334333654054465343003434406346465433440434444330364534565056636553350466366665444065035404305464055003066363646443506034056346345655363030563036546534303465653566303600330536353436333434335066330534556336543636533063664463644460404363630445655330334564353535300043333343453445064535566334303000404403305345440056456654646036363046453663443444334334364535344333565433446553504546563640503053635566330536553405563434335030303564065630335564353604646660446546334655646034645633405050533554434534053504534406566040353534050034445565535546605453535630533063453436563543544605056506046536044436563044440033640300355503465030335635304543503564033033543435664056553346400556563443446463556044360305553306600055344056563654053560300656335553436354636400330664340433345565444300563355536004040300460065555046565654663363660654645500503003630650436003654440605564505646630346355433505630004404465444333403544403353305434636435445550503645406353043335346063545366004536504054343043033336453304430466340456433534534536333403355666553334454634033053654043354455536650536533346333434535463464434035503535343436364653634550440500435666345606454665640553644340635346054344304443504645543556060034444434435605505646056505054364430550453306065566035536005634355634443355443436333404335360534644440440545463035040636333636444354445040543006605653655360446635564036306434533006445454004534466356330350345040343305300544054345636344534604554430666300406443045344343330335336056053464306403345334566006634436303345550653600560654463633334506505630605464635403660354436456553634040053405653564645635345460353400465565535430003533663334533506646403603630434654540343400453654430433000355666550305343654336630366533560345044400350604444543035603563050306033344665435655030343536346556005546533663660360430535500665336003655054533553303006404450450634554536533463300535503360036660060405034434464335060446450303343443055545544336343330055464646043364344636436445334043030353350433055033603455534653363030644354304633634536330666330045505005663635345635334344404364433545505543543504363456364430445430535344605443000655533404304553404646665353600035505645536635353336406044460044504306453444053003540444443605544643530663430364663560334463546064033535564663345340634036465533560355556644334504545366446435043330000534403446344565465064664063655546056533536530460566530553366043363553453456305045534303640053455366366565536434064604033444343434050564556366435335343633056430044454646560054446633606044356563444330444403453356403504340435330335464553365063505053666400503343035363405346543530544463644305400303650645653340666304453636660043403354334663054500044040500435660540656663334434336336363453544360300356304455653446334043305004353335654660666335543340534444563060645650564536434443463400404005455505436450500000063443330566564665363305643355000563435365655645656433406335063566553500653635654630534444345055343545305666664644306463460036046463034550033543340354543564563503564656055403630566030534404035343554053034363044364045365544355303463566306545363406335534546646653500550646504344500345435643630505536343436300363643530353436606330535535304635565454054634506555366353545345355400430305533654000345360535005653063443654636635650630534606340066305304566354633455355455503600054533434356446356440350530650453503444530334353043044603354035330305450533640405355666543060563433333663636354435463033530543635355430066600034363434554334333065006336554643463563440005464440305003046440443634503300000633634654433533665605665343540005454463634435034463446603640555543540533344640433530543355406440604656644404605530003653553300653533334050334644403600464446460453606646504355350553343646335604355344465540443303500303655540656333503345330533456454450036666053604334340533036436336553535030550563343006003330555604503650663344663353444343653450356546335533503654563304506665535636306444056464503445466556453534336536440406656533060345640545544403630555336443430440603353034634556566344464343330053634304340665403044333433450543535530554563303565553304360336430335065665366063533063460635034533643053064546066036350355364434403564433444643653546504430646436035564633456530303564346033503636400004563555304646663433053043636330443444434545340353456343360363635030063464036330655043460505456545343406653406403335555066043040504443034063506000333553005635035644500656303030065603630653035054303055460454534033546465335333565453554563046305405444433504554604563334034644435660463463063500334600045334336050344466654053533004446555543553633656640334005336503056633463644006663534363303406344503035354304433604636333345630035066355354333003344646665445540045440564543500305553344056334545404344365605545040055334635300654304564403405530555534306344666635536040454454454436343564066633305646650543634053335334450346434300360600534655040034065403404555303435534306645354344665640060354334000650353503650003546535356346350400553433650660034343635030336335564364334536654443540044036303306360554344433033543364443033605035353446336404453306045063060603036553644055540464463055550545444333065544403534354655356400640354460050465545363344350043656055435366634033045360365653505054350436656634436604333433530533363636043000634404656330665033035055345654345634436553363436656453433363543404503443454456645363344340505304503036530553363000633054430503045304005335335340306333430463554655443606544053550346363034035353544044553030334305466364063434460554506643556536343006544030365546560005356333453533003404553354035430466444034553606435543303606665035443353633353366300366536055446456430533333564440564336533353455553665365645400400534054630634306653646560044540456345533434634654536545360355436356633450635445333006563656464364643446356343355635663503560450644446543335604443546033454333406303666665060360350365044034645664400456434534566640536065430463504033443546044300363455345635464350666454450636440355546036350366400645365356404344450453635364353634043650305033063545363046606356355604330543604063466644305533353665333464333354663634354645433345356404404556040406434544454345464333645530336500050535433433630464536335550556636504340045344356466666665034350063335553505430456604346346334443665535660354444543440436406046000654564446436305335544355455343303333345446563453530534653465366650333534053335056336304304000060055640654053344000456644640504066063660543303630503034660036544435364054544653065434033533360406443565306634656534560043343563363656444456664540304650550345606004403606046455653433636355533330303005433456405563556353330534535665005666300366345365004433443540553066530004554664344055436333553345345063634064050634356006506443046446366333333065346665050603665335044366534444050063546304463335643530343343006033545443646653665405655554353435545403605353303536300303455306604463503306560036656530354004364545643440403360303066460443450044534633440603656306354346536435433464464433455000336334504465646643343430405433655534554434430460334463543030644433440334640630346064304443403544533436636563455064443633645633550035304403544045303633604436536403604363550443560300443660340655356450346533003335033366453455545443366460440534430645530340303456645434036360304346305034406003344456003006330665650645033545305463460364403453056534534533300330044646535665555554033505360334500405343454464635565655455503464555554030430005665306334660333036465644500643004460335653563304344034430304635434033303304405454663645064043033430045064550056634453300036344646636436335655565445354053640643034350665333366445650605464503305063353430443643563500553363343565335555654003556660353346400036554033350563036353664455633540463305646453460063600500454363656555364363303604665664363555004440336066640364504530634446446544335664646304033046344355433356633530363444333340353355005606565560435364053556360466006436450436034465436356350546445333534335345033334433063444300534443536600505304650556404454555663545454053033340363045430536056443565454530546605635343664004033543644033560035666556643630604345633604543354034435355345303633564433650654530606366653034653030034340446566604334663366344354453066603634330333530630003533634305350000004554046665404306553443504300635036560663465355645633345663436000445066605333033064453656303666364360666536306335444356354553650666340344505355550466563403455363646055545003033343433440353506633344665405455636056036400305646033553303345305365503466306334436533555006053534453443345035344340636030505463055036333045454006354630655450354430453346455030656535400434350533446035060346555343506646636355033360436054466046365450455444555456543030556344335600003464633636643444030634546404500603046365004636353554506650550504554500350604344634543445334406366366454450454545050655603364046533354654633433440564455444306653000606446605333644035433406430635...\n",
            "Total predictions length: 10000\n",
            "Distinct value count: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Su šiuo modeliu gavome 99 % accuracy.\n",
        "* Sukurta CustomDataset klasė plečia TensorDataset, leidžiančią taikyti transformacijas tiesiogiai gaunant duomenis.\n",
        "* CNN modelis, paremtas iš anksto apmokyta DenseNet architektūra.\n",
        "* Svarbu stabdyti modelį, kai kas epochą tikslumas pradeda mažėti.\n"
      ],
      "metadata": {
        "id": "ad7jdpYdjZyN"
      }
    }
  ]
}